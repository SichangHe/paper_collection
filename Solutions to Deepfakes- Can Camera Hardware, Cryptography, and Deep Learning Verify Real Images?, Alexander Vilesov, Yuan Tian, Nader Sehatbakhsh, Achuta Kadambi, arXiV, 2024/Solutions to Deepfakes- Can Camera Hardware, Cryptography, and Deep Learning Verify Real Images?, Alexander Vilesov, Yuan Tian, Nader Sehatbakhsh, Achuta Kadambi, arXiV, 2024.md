# Solutions To Deepfakes: Can Camera Hardware, Cryptography, And Deep Learning Verify Real Images?

ALEXANDER VILESOV, YUAN TIAN, NADER SEHATBAKHSH, ACHUTA KADAMBI

![0_image_0.png](0_image_0.png)

UNIVERSITY OF CALIFORNIA, LOS ANGELES (UCLA)
Fig. 1. **Photo of a lighthouse generated by AI [3] on the left and a real photo on the right.** As synthetic image generators improve, the near future will see synthetic images being generated that are visually indistinguishable from real images. Distinguishing between real and synthetic is going to be extremely important and existing infrastructure is not sufficient.

#### Acm Reference Format:

Alexander Vilesov, Yuan Tian, Nader Sehatbakhsh, Achuta Kadambi, University of California, Los Angeles (UCLA). 2024. Solutions to Deepfakes: Can Camera Hardware, Cryptography, and Deep Learning Verify Real Images?. 1, 1 (July 2024), 6 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

## 1 Introduction

The exponential progress in generative AI poses serious implications for the credibility of all real images and videos. There will exist a point in the future where 1) digital content produced by generative AI will be indistinguishable from those created by cameras, 2) highquality generative algorithms will be accessible to anyone, and 3) the ratio of all synthetic to real images will be large. It is imperative to establish methods that can separate real data from synthetic data with high confidence. We define 'real images' as those that were produced by the camera hardware, capturing a real-world scene.

Any synthetic generation of an image or alteration of a real image Author's address: Alexander Vilesov, Yuan Tian, Nader Sehatbakhsh, Achuta Kadambi University of California, Los Angeles (UCLA). 

#### 

for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

©
 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.

ACM XXXX-XXXX/2024/7-ART https://doi.org/10.1145/nnnnnnn.nnnnnnn through generative AI or computer graphics techniques is labeled as a 'synthetic image'. To this end, this document aims to:
(1)
 present known strategies that can be employed to verify which images are 'real'
(2)
 weight the strengths and weaknesses of these strategies
(3)
 suggest additional improvements to alleviate shortcomings We begin in section 2 with a summary of generative AI capabilities. We contextualize the primary efforts that are being made to distinguish between real and synthetic media: namely methods that are detection-based in section 3 and encryption-based in section 4. We believe that encryption-based methods are more future-proof and suggest methods in which they should be incorporated to improve robustness and transparency in section 5. We conclude, in section 6, by stating the impacts of what it would mean if we can secure our digital future.

## 2 Current And Future Capabilities Of Generative Ai

The advent of GANs [31] in 2014 has allowed the popularity and photorealism of synthetic media creation, or "deepfakes", to skyrocket in the recent decade. Some recent applications include face or identity swapping (swapping the face or identity of a target image onto a different source image) [11, 14, 23, 46, 57, 59, 64, 87, 94], body puppetry (giving a target image the same body posture, gesture,

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed
2 - Alexander Vilesov, Yuan Tian, Nader Sehatbakhsh, Achuta Kadambi Table 1. **A rapid increase in the quality and number of synthetic** photos poses several problems to how we can safely navigate digital media. We identify the primary issues to consider and describe potential solutions in section 4.

| Open Problems                 | Advocated Solutions            |
|-------------------------------|--------------------------------|
| Authenticity of Digital Media | Verification through cryptog                                |
| (deepfake or real?)           | raphy implemented by camera    |
|                               | manufacturers.                 |
| Printout Spoofs               | 3D Sensing and light transport |
| Searching for Real Images and | Creating new file formats for  |
| Consumer Clarity              | photos produced by cameras.    |

or movements of the source image) [12, 26, 29, 32, 44, 48, 65, 76–
78, 80, 85, 86, 90], or lip-synching (creating mouth movement in the target image to match any source input audio) [28, 38, 43, 74, 91].

The recent introduction of diffusion-based generative modeling has pushed the boundaries of synthetic media creation even more [83]. This class of generative models progressively perturbs input images with noise, and then removes this noise to generate new output images. In the past few years, standard DDPMs [35, 67], score-based generative models [69, 70], as well as SDE models [41, 68, 71] have all arisen as popular formulations with their own set of advantages and disadvantages. Concurrently, further advancements are being made every day on aspects such as more efficient sampling [18, 24, 51, 54, 88, 89, 93] or better likelihood estimation [6, 36, 42, 50, 56], allowing the generative process to become faster and better samplers of the target distribution. The introduction of new architectures like StableDiffusion [62], which performed generative sampling on a learned latent space as opposed to the image space, led to pushing the boundary even further on the photo-realism and speed of generated images. As these models progressively become better and our access to training data increases in the coming years [30, 79], both the threats and benefits of generative modeling and synthetic media creation will intensify.

The Threats and Benefits of Synthetic Media. As our capacity to generate more and more realistic synthetic media increases, so too does our capacity to benefit from the capabilities of generative modeling. Deepfakes have been used for educational purposes, such as the use of a synthetic Barack Obama teaching people about the dangers of deepfakes [15]. They have also been used commercially in fields like entertainment or marketing [55]. Most notably, deepfakes have been used to facilitate social interaction through language barriers or diseases like ALS [15].

Unfortunately, the advent of generative modeling technology has brought with it a massive host of unwanted threats to security. Generative models' ability to depict real-world individuals and entities in fabricated settings can have severe consequences for individuals, businesses, or even nations. [10, 15, 22]. In 2021, the DOD published an analysis of the threats of deepfake technology, which included its ability to portray celebrities, business owners, and even political figures in unwanted and potentially harmful manners [10]. The article gave numerous examples of how deepfake technology could be used for such unwanted threats as falsifying evidence in criminal court, influencing national elections, or creating non-consensual 

pornographic material. With the introduction of diffusion models and further improvements in generative modeling in the years that followed this report, the frequency and intensity of threats have only increased. This is why, crucially, methods should be developed to detect the different forms of synthetic media.

## 3 Verification Through Detection

One of the most common existing solutions to the problem of identifying synthetic media is to train machine learning systems designed to identify and detect synthetic images, videos, etc. At a high level, we can define this technique as training a system D :  → (),
where D is a detector that takes in an image as input and outputs the probability of it being real.

The design of these detectors can vary a lot, as they can learn to focus on a variety of different cues ranging from systems that look at image statistics and small details to systems that look for biological signs of humans as cues.

DeepFake Detection. As our generative AI methods improve every day, the systems we make to detect generated media need to improve at a commensurate rate to work properly. Methods like FAC- TOR rely on similarity scores between "factual information" given by texts, images, or videos in a pre-trained latent space to obtain a truth rating
 () [61]. Other methods utilize popular convolutional models like EfficientNetB4 with attention and ensemble training to get SOTA quality results on detecting manipulated or fake images [9]. To facilitate the research and discovery of new methods of video deepfake detection, datasets like DFDC (DeepFake Detection Challenge) were produced with over 5K videos across different genders, skin tones, and age groups [25]. The current highest performer on the DFDC involves using vision transformers with an Efficient- Net B0 encoder [19]. The DeepFake detection field [33, 58, 92] is rapidly expanding, however, most works are focused on differentiating between fake and real faces and not necessarily fake and real images. Recently, with the increase in the use of diffusion models, several works have aimed at image detection of diffusion-generated content [21, 49, 81].

Arms Race between Generation and Detection. Detection and generation form two components of an adversarial pair. Therefore, each of these can be refined, given the other, to be resilient to the other. This creates an adversarial arms race: the detector can never be guaranteed to be robust to the generator (since the generator may have been refined on the performance of the detector), and hence will need to be refined on all generators. Given this never-ending cycle, detection-based methods can never truly be robust to detecting synthetic media. In the following section, we describe another approach that utilizes encryption to guarantee the authenticity of real digital media.

## 4 Verification Through Encryption

A more robust solution involves cryptographically sealing providence information into a digital media's metadata so that consumers of the content can verify its integrity. The Coalition for Content Provenance and Authenticity (C2PA) [1, 63] is an organization whose goal is to develop technical standards that can enable

Fig. 2. **C2PA does not guarantee the realness of digital media.** We show an example of taking an image of a deepfake using a camera app implementing

![2_image_0.png](2_image_0.png) C2PA [2]. The verification of the image will still pass and end-users will be misled into believing that the image is truly real. 

such a solution. The C2PA standard proposes a variety of use cases and flexibility, however, we focus on how it can be used to verify whether an image was produced by a camera. In what follows, we detail the salient aspects of how this standard can be used to separate real and synthetic images.

PKI for Camera Generated Digital Media. The verification of providence is facilitated by incorporating principles from the public key infrastructure (PKI) paradigm that powers SSL/TLS-based internet communications. PKI's goal is to establish a secure transfer of information between two parties. From a cryptography point of view, this is achieved through an interplay between public/private key pairs and a central authority (CA) that all involved parties trust in [8]. In the case of verifying the authenticity of digital media, we are interested in the following question: how can a user know that a photo was really taken by a camera? This is accomplished in two steps. Before a camera ever takes a photo, the manufacturer of the camera must generate a public and private key pair and register the public key with a central authority. The CA then vets the manufacturer to make sure they are who they say they are and creates a digital signature that the manufacturer can now use. Upon taking a photo, a camera can then sign the data by encrypting a hash [72] of the data using its private key and appending it with the digital signature to the photo's metadata. When the photo is distributed, a consumer can then perform two verification steps. First, the consumer checks that the image is unaltered by decrypting the attached hash using the manufacturer's public key and comparing it with the hash generated by the image data the consumer received. If the hashes are equal, then the image is unaltered. Next, the consumer checks the digital signature with the CA and ensures that the public key is in the trust list of the CA. Then the consumer can be confident that the image was produced by a camera and has been unaltered.

While PKI-based methods provide a method for verifying that an image came from a camera, it still requires massive coordination between camera manufacturers and is not entirely robust to all forms of spoofing. In the following section, we propose additional modifications to PKI-based methods in the future to become a reliable method for distinguishing between real and synthetic digital media.

## 5 Additional Measures

Required Steps for Adoption. The PKI-based approach can only work if it is adopted on a large scale by everyone and the primary burden is on camera manufacturers and the development of a CA that can support such an infrastructure. To achieve a future where it is possible to verify that an image truly came from a camera, several steps must be taken. All camera manufacturers must add the described PKI strategy into their camera pipelines so that each photo can be signed using their private keys and signatures. Secondly, all camera manufacturers must collaborate in creating a unified CA that is devoted to storing a trust list of all public keys that are being used by cameras. The methods for distributing and presenting images must be cognizant of the extra meta-data that digital media may have. These methods must be designed so that they do not accidentally remove the metadata that is used for verification as well as ideally provide their own checks that an image is indeed produced by a camera. The greatest barrier to incorporating this method is in making everyone use it as well as educating media consumers.

Spoofing. Even when the described approach is implemented correctly, there are still methods by which one can make synthetic images appear real. As mentioned before, the PKI-based strategy only ensures that images were taken by a camera. If the image is altered in any way, the verification process will detect it and flag the image as not real. However, a viewer of an image can still be tricked into believing that a synthetic image is real, barring the possibility that the manufacturer's private keys are leaked. One can still take an image of a synthetic image that is rendered on some surface like a screen or photo using a PKI-enabled camera. We show an example of this process in fig. 2, where we use the app ProofMode [2], a program that implements the C2PA standard, as a surrogate for camera hardware. First, a synthetic image is generated and then a picture of it is taken using a camera with PKI signing abilities. Any consumer of the image will be sure that the image was created by a camera and assume that it is real, but it is still a rendition of a synthetically generated image.

Prevention of Spoofing. The prevention of these types of deceptions is non-trivial. The problem formulation is to create a camera setup that has the following properties:
(1)
 It is able to differentiate between natural images of a 3D scene and a 2D scene such as a computer monitor or a flat surface upon which an image can be projected.

(2)
 It is not prohibitively expensive. The PKI system will only work with cameras that are robust to spoofing which necessitates a camera setup that is easy to integrate into most systems.

The design of a camera system should optimize its parameters so that it would be difficult for an adversary to simulate an arbitrary image and spoof the system. The design of a camera system can be seen as choosing what regions of the domain,
 , of the plenoptic function [4],
 (, ), should be sampled, where  is a scene. While the plenoptic function's domain is vast, spanning all wavelengths, viewing angles, and other properties of light such as polarization, the cost of sensing such a domain,
 () increases with its size. Informally, the problem can then be viewed as the following optimization problem:
E
 [log ( (, )] + E
 [log 1 − ( (,)] +  (), (1)
where is a discriminator between real and fake images produced max
,
by the plenoptic function to sense a particular domain
 .

 
 and
 
are random variables for real scenes and adversarially generated scenes that are intended to appear as a real scene.

Assuming a perfect setup, detection is difficult with only access to one image from a monocular camera due to camera projection of 3D to 2D space, despite prior work on screen recapture detection that typically detects the moiré pattern [13, 16, 45, 53]. A more robust solution is to detect whether the photo is inherently of a 3D scene. In the case of photos, we are typically restricted to either a single camera or a multi-camera setup. In the case of a single camera, the majority of available techniques rely on structure from motion [5, 52, 66]. Even small jitters caused by a hand holding a camera or smartphone can reveal the 3D nature of a scene [17, 37, 84]. More robust methods are available with a multi-camera setup such as stereo-based methods [34, 52]. With stereo-based methods, we are able to find correspondences between cameras and triangulate them to find their depth. Here, the detection of an adversarially generated scene can be handled by detecting whether the cameras are viewing a plane. However, even this system is prone to spoofing since attacking this system is tantamount to creating a virtual reality headset for a stereo camera. A more elaborate spoofing system can take advantage of the recently proposed Split-Lohmann multifocal displays [60] that would also be able to fool depth-fromdefocus [73, 75, 82] methods. Fortunately, we have access to many other dimensions of light that are difficult to simulate. For example, smartphones may incorporate new types of sensors such as lidar [20, 47], polarization-based sensing [39, 40], or ToF [7, 27] into their camera systems, all of which are capable of detecting 3D features of a scene. Other solutions may even rely on subtly changing the camera's ISP; for example, spatially altering the Bayer pattern such that the spectral sensitivities of different pixels vary or sparsely sampling a set of pixels to be polarization sensitive could be a lowcost solution to detecting screens. Finding a robust and inexpensive solution to eq. (1) is non-trivial. The better solutions appear to be the ones that take advantage of additional properties of light since it becomes more difficult to pass on these properties to an adversarially generated image, albeit at an increased sensor cost.

Unfortunately, there exist plenty of real images that are trying to depict a planar surface such as a painting, mural, or a text document without nefarious intent. An anti-spoofing method should not discount such types of media portrayals. A potential solution to this problem is to add a binary label to images that indicate whether an image is primarily a depiction of a 2D or 3D scene. Upon verifying that an image was produced by a camera, viewers of the image should also be told whether the content is of a 2D or 3D nature. It is then up to the viewer to judge whether a particular image is misleading given that information.

New File Types: Faster Searching and Viewer Confidence.

While standards such as those proposed by the C2PA can create a world where images can be verified to be taken by a camera, it does not make the process for searching for real images simple. There are many situations where users may want to search for images that are only taken by a camera. For example, it may be desirable to only train or benchmark certain AI algorithms in the domain of real images. The process of creating such datasets may be timeconsuming if it requires a program to search through all images and check their metadata to see if it is real.

The addition of providence data to a digital media's metadata has several drawbacks. A simple search by file name will not immediately determine if the image has the right type of metadata to prove if it is real and it is simple to remove the providence data from the metadata. File extensions typically serve to indicate the characteristic or intended use of a file. The current file formats for digital media currently do not indicate whether a file format is intended for data that was created by camera hardware. Therefore, a new file format for digital media created by cameras can alleviate these problems. The new file format will include the original data and file format (e.g. .png, .jpg, .mp4) with a new extension (e.g. .png.real, .jpg.real, .mp4.real), but also include a mandatory data field to support PKI-based verification. The programs that read and write such new files can only complete the operation if the mandatory data fields are filled out properly. Moreover, such programs should also incorporate checks to make sure that the image being saved can be verified to be real. With such a new file extension, the set of images that needs to be searched becomes smaller and easier to manage. Moreover, users of the files have more confidence in using such files since the intended use is only for real images. The downside to a new file format is that it requires everyone to add extra support for it.

## 6 What Is At Stake?

With generative AI and inevitable progress, the rate, quality, and ease with which synthetic images can be created will be astonishing.

It will flood our databases and make it impossible to really know which images are real or fake. Bad actors will be able to create large amounts of highly convincing images and videos to spread disinformation that would be difficult for a layman to disqualify as synthetic or fake. It then becomes imperative that we establish protocols for verifying real digital media before we have reached such a point in the technical advancement of AI. Establishing and implementing such protocols will be a great undertaking that we believe will require careful coordination and co-design of cryptography, camera hardware, and machine learning components. Unfortunately, every day that we have not fully established such protocols, the majority of real images that have been taken today or in the past will not have the potential to be verified as real images. We hope to introduce the broader community to existing methods to distinguish between real and synthetic images, as well as point out the steps required to make these methods robust for the inevitable near future.

## References

[1]
 C2pa: An open technical standard providing publishers, creators, and consumers the ability to trace the origin of different types of media. http://https://c2pa.org/. Accessed: 2024-02-01.

[2]
 Proofmode: Capture, share, and preserve verifiable photos and videos. https:
//https://proofmode.org/about. Accessed: 2024-02-01.

[3]
 stability.ai: Stable diffusion 3. https://stability.ai/news/stable-diffusion-3. Accessed: 2024-02-23.

[4]
 Adelson, E. H., Bergen, J. R., et al.

 The plenoptic function and the elements of early vision, vol. 2. Vision and Modeling Group, Media Laboratory, Massachusetts Institute of . . . , 1991.

[5]
 Agarwal, S., Furukawa, Y., Snavely, N., Simon, I., Curless, B., Seitz, S. M., and Szeliski, R.

 Building rome in a day.

 *Communications of the ACM 54*, 10 (2011),
105–112.

[6]
 Bao, F., Li, C., Zhu, J., and Zhang, B.

 Analytic-dpm: an analytic estimate of the optimal reverse variance in diffusion probabilistic models.

 *arXiv preprint* arXiv:2201.06503 (2022).

[7]
 Belhedi, A., Bartoli, A., Bourgeois, S., Hamrouni, K., Sayd, P., and Gay-
Bellile, V.

 Noise modelling and uncertainty propagation for tof sensors. In Computer Vision–ECCV 2012. Workshops and Demonstrations: Florence, Italy, October 7-13, 2012, Proceedings, Part III 12 (2012), Springer, pp. 476–485.

[8]
 Benantar, M.

 The internet public key infrastructure.

 *IBM Systems Journal 40*, 3
(2001), 648–665.

[9]
 Bonettini, N., Cannas, E. D., Mandelli, S., Bondi, L., Bestagini, P., and Tubaro, S.

 Video face manipulation detection through ensemble of cnns. In 2020 25th international conference on pattern recognition (ICPR) (2021), IEEE, pp. 5012–5019.

[10]
 Brooks, T., Princess, G., Heatley, J., Jeremy, J., Kim, S. M. S., Parks, S., Reardon, M., Rohrbacher, H., Sahin, B., Shani, S., et al.

 Increasing threats of deepfake identities.

 *US Department of Homeland Security, https://www. dhs.*
gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0. pdf (2021).

[11]
 Cao, M., Huang, H., Wang, H., Wang, X., Shen, L., Wang, S., Bao, L., Li, Z., and Luo, J.

 Unifacegan: a unified framework for temporally consistent facial video editing.

 *IEEE Transactions on Image Processing 30* (2021), 6107–6116.

[12]
 Chan, C., Ginosar, S., Zhou, T., and Efros, A. A.

 Everybody dance now. In Proceedings of the IEEE/CVF international conference on computer vision (2019),
pp. 5933–5942.

[13]
 Chen, C., Lin, L., Chen, Y., Li, B., Zeng, J., and Huang, J.

 Cma: A chromaticity map adapter for robust detection of screen-recapture document images. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2024),
pp. 15577–15586.

[14]
 Chen, R., Chen, X., Ni, B., and Ge, Y.

 Simswap: An efficient framework for high fidelity face swapping. In Proceedings of the 28th ACM International Conference on Multimedia (2020), pp. 2003–2011.

[15]
 Chesney, B., and Citron, D.

 Deep fakes: A looming challenge for privacy, democracy, and national security.

 *Calif. L. Rev. 107* (2019), 1753.

[16]
 Choi, H.-Y., Jang, H.-U., Son, J., Kim, D., and Lee, H.-K.

 Content recapture detection based on convolutional neural networks. In Information Science and Applications 2017: ICISA 2017 8 (2017), Springer, pp. 339–346.

[17]
 Chugunov, I., Zhang, Y., and Heide, F.

 Shakes on a plane: Unsupervised depth estimation from unstabilized photography. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2023), pp. 13240–13251.

[18]
 Chung, H., Sim, B., and Ye, J. C.

 Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2022), pp. 12413–12422.

[19]
 Coccomini, D. A., Messina, N., Gennaro, C., and Falchi, F.

 Combining efficientnet and vision transformers for video deepfake detection. In International conference on image analysis and processing (2022), Springer, pp. 219–229.

[20]
 Collis, R.

 Lidar.

 *Applied optics 9*, 8 (1970), 1782–1788.

[21]
 Corvi, R., Cozzolino, D., Zingarini, G., Poggi, G., Nagano, K., and Verdoliva, L.

 On the detection of synthetic images generated by diffusion models. In ICASSP
2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP) (2023), IEEE, pp. 1–5.

[22]
 Dagar, D., and Vishwakarma, D. K.

 A literature review and perspectives in deepfakes: generation, detection, and applications.

 *International journal of multimedia* information retrieval 11, 3 (2022), 219–289.

[23]
 Dale, K., Sunkavalli, K., Johnson, M. K., Vlasic, D., Matusik, W., and Pfister, H.

 Video face replacement. In
 *Proceedings of the 2011 SIGGRAPH Asia conference*
(2011), pp. 1–10.

[24]
 Dockhorn, T., Vahdat, A., and Kreis, K.

 Score-based generative modeling with critically-damped langevin diffusion.

 *arXiv preprint arXiv:2112.07068* (2021).

[25]
 Dolhansky, B., Howes, R., Pflaum, B., Baram, N., and Ferrer, C. C.

 The deepfake detection challenge (dfdc) preview dataset.

 *arXiv preprint arXiv:1910.08854* (2019).

[26]
 Doukas, M. C., Koujan, M. R., Sharmanska, V., Roussos, A., and Zafeiriou, S.

Head2head++: Deep facial attributes re-targeting.

 IEEE Transactions on Biometrics, Behavior, and Identity Science 3, 1 (2021), 31–43.

[27]
 Freedman, D., Smolin, Y., Krupka, E., Leichter, I., and Schmidt, M.

 Sra: Fast removal of general multipath for tof sensors. In
 *Computer Vision–ECCV 2014: 13th* European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I
13 (2014), Springer, pp. 234–249.

[28]
 Fried, O., Tewari, A., Zollhöfer, M., Finkelstein, A., Shechtman, E., Goldman, D. B., Genova, K., Jin, Z., Theobalt, C., and Agrawala, M.

 Text-based editing of talking-head video.

 *ACM Transactions on Graphics (TOG) 38*, 4 (2019), 1–14.

[29]
 Gafni, O., Ashual, O., and Wolf, L.

 Single-shot freestyle dance reenactment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2021), pp. 882–891.

[30]
 Ganguli, D., Hernandez, D., Lovitt, L., Askell, A., Bai, Y., Chen, A., Conerly, T., Dassarma, N., Drain, D., Elhage, N., et al.

 Predictability and surprise in large generative models. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (2022), pp. 1747–1764.

[31]
 Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
Ozair, S., Courville, A., and Bengio, Y.

 Generative adversarial networks, 2014.

[32]
 Gu, K., Zhou, Y., and Huang, T.

 Flnet: Landmark driven fetching and learning network for faithful talking facial animation synthesis. In
 *Proceedings of the AAAI*
conference on artificial intelligence (2020), vol. 34, pp. 10861–10868.

[33] Guarnera, L., Giudice, O., and Battiato, S. Deepfake detection by analyzing convolutional traces. In
 *Proceedings of the IEEE/CVF conference on computer vision* and pattern recognition workshops (2020), pp. 666–667.

[34]
 Hartley, R., and Zisserman, A.

 *Multiple view geometry in computer vision*.

Cambridge university press, 2003.

[35]
 Ho, J., Jain, A., and Abbeel, P.

 Denoising diffusion probabilistic models.

 Advances in neural information processing systems 33 (2020), 6840–6851.

[36]
 Huang, C.-W., Lim, J. H., and Courville, A. C.

 A variational perspective on diffusion-based generative models and score matching.

 Advances in Neural Information Processing Systems 34 (2021), 22863–22876.

[37]
 Im, S., Ha, H., Choe, G., Jeon, H.-G., Joo, K., and Kweon, I. S.

 High quality structure from small motion for rolling shutter cameras. In Proceedings of the IEEE International Conference on Computer Vision (2015), pp. 837–845.

[38]
 Jamaludin, A., Chung, J. S., and Zisserman, A.

 You said that?: Synthesising talking faces from audio.

 *International Journal of Computer Vision 127* (2019),
1767–1779.

[39]
 Kadambi, A., Taamazyan, V., Shi, B., and Raskar, R.

 Polarized 3d: High-quality depth sensing with polarization cues. In
 *Proceedings of the IEEE international* conference on computer vision (2015), pp. 3370–3378.

[40]
 Kalra, A., Taamazyan, V., Rao, S. K., Venkataraman, K., Raskar, R., and Kadambi, A.

 Deep polarization cues for transparent object segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2020), pp. 8602–8611.

[41]
 Karras, T., Aittala, M., Aila, T., and Laine, S.

 Elucidating the design space of diffusion-based generative models.

 *Advances in Neural Information Processing* Systems 35 (2022), 26565–26577.

[42]
 Kingma, D., Salimans, T., Poole, B., and Ho, J.

 Variational diffusion models. In Advances in Neural Information Processing Systems (2021), M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, Eds., vol. 34, Curran Associates, Inc., pp. 21696–21707.

[43]
 Lahiri, A., Kwatra, V., Frueh, C., Lewis, J., and Bregler, C.

 Lipsync3d: Dataefficient learning of personalized 3d talking faces from video using pose and lighting normalization. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2021), pp. 2755–2764. 

[44]
 Lee, J., Ramanan, D., and Girdhar, R.

 Metapix: Few-shot video retargeting.

arXiv preprint arXiv:1910.04742 (2019).

[45]
 Li, J., Kong, C., Wang, S., and Li, H.

 Two-branch multi-scale deep neural network for generalized document recapture attack detection. In
 *ICASSP 2023-2023 IEEE*
International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2023),
IEEE, pp. 1–5.

[46]
 Li, L., Bao, J., Yang, H., Chen, D., and Wen, F.

 Advancing high fidelity identity swapping for forgery detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2020), pp. 5074–5083.

[47] Li, Y., Yu, A. W., Meng, T., Caine, B., Ngiam, J., Peng, D., Shen, J., Lu, Y., Zhou, D., Le, Q. V., et al.

 Deepfusion: Lidar-camera deep fusion for multi-modal 3d object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2022), pp. 17182–17191.

[48]
 Liu, L., Xu, W., Zollhoefer, M., Kim, H., Bernard, F., Habermann, M., Wang, W., and Theobalt, C.

 Neural rendering and reenactment of human actor videos.

ACM Transactions on Graphics (TOG) 38, 5 (2019), 1–14.

[49]
 Lorenz, P., Durall, R. L., and Keuper, J.

 Detecting images generated by deep diffusion models using their local intrinsic dimensionality. In Proceedings of the IEEE/CVF International Conference on Computer Vision (2023), pp. 448–459.

[50]
 Lu, C., Zheng, K., Bao, F., Chen, J., Li, C., and Zhu, J.

 Maximum likelihood training for score-based diffusion odes by high order denoising score matching. In
 *International Conference on Machine Learning* (2022), PMLR, pp. 14429–14460.

[51]
 Lyu, Z., Xu, X., Yang, C., Lin, D., and Dai, B.

 Accelerating diffusion models via early stop of the diffusion process.

 *arXiv preprint arXiv:2205.12524* (2022).

[52]
 Ma, Y., Soatto, S., Košecká, J., and Sastry, S.

 An invitation to 3-d vision: from images to geometric models, vol. 26. Springer, 2004.

[53]
 Mahdian, B., Novozámsky, A., and Saic, S.

`
 Identification of aliasing-based patterns in re-captured lcd screens. In 2015 IEEE International Conference on Image Processing (ICIP) (2015), IEEE, pp. 616–620.

[54]
 Meng, C., Rombach, R., Gao, R., Kingma, D., Ermon, S., Ho, J., and Salimans, T.

 On distillation of guided diffusion models. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition (2023), pp. 14297–14306.

[55]
 Mirsky, Y., and Lee, W.

 The creation and detection of deepfakes: A survey.

 ACM
Computing Surveys (CSUR) 54, 1 (2021), 1–41.

[56]
 Nichol, A. Q., and Dhariwal, P.

 Improved denoising diffusion probabilistic models. In
 *International Conference on Machine Learning* (2021), PMLR, pp. 8162–
8171.

[57]
 Nirkin, Y., Keller, Y., and Hassner, T.

 Fsgan: Subject agnostic face swapping and reenactment. In
 *Proceedings of the IEEE/CVF international conference on computer* vision (2019), pp. 7184–7193.

[58]
 Nirkin, Y., Wolf, L., Keller, Y., and Hassner, T.

 Deepfake detection based on discrepancies between faces and their context.

 *IEEE Transactions on Pattern* Analysis and Machine Intelligence 44, 10 (2021), 6111–6121.

[59]
 Peng, B., Fan, H., Wang, W., Dong, J., and Lyu, S.

 A unified framework for high fidelity face swap and expression reenactment.

 IEEE Transactions on Circuits and Systems for Video Technology 32, 6 (2021), 3673–3684.

[60]
 Qin, Y., CHEN, W., O'TOOLE, M., and Sankaranarayanan, A. C.

 Split-lohmann multifocal displays.

 *ACM Trans. Graph 42*, 4 (2023).

[61]
 Reiss, T., Cavia, B., and Hoshen, Y.

 Detecting deepfakes without seeing any.

arXiv preprint arXiv:2311.01458 (2023).

[62]
 Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.

 Highresolution image synthesis with latent diffusion models. In
 *Proceedings of the* IEEE/CVF conference on computer vision and pattern recognition (2022), pp. 10684–
10695.

[63]
 Rosenthol, L.

 C2pa: the world's first industry standard for content provenance.

In
 *Applications of Digital Image Processing XLV* (2022), vol. 12226, SPIE, p. 122260P.

[64]
 Rossler, A., Cozzolino, D., Verdoliva, L., Riess, C., Thies, J., and Niessner, M.

Faceforensics++: Learning to detect manipulated facial images. In Proceedings of the IEEE/CVF international conference on computer vision (2019), pp. 1–11.

[65]
 Sanchez, E., and Valstar, M.

 A recurrent cycle consistency loss for progressive face-to-face synthesis. In
 *2020 15th IEEE International Conference on Automatic* Face and Gesture Recognition (FG 2020) (2020), IEEE, pp. 53–60.

[66]
 Schonberger, J. L., and Frahm, J.-M.

 Structure-from-motion revisited. In Proceedings of the IEEE conference on computer vision and pattern recognition (2016), pp. 4104–4113.

[67]
 Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.

 Deep unsupervised learning using nonequilibrium thermodynamics. In
 *International* conference on machine learning (2015), PMLR, pp. 2256–2265.

[68]
 Song, Y., Durkan, C., Murray, I., and Ermon, S.

 Maximum likelihood training of score-based diffusion models.

 *Advances in Neural Information Processing Systems* 34 (2021), 1415–1428.

[69]
 Song, Y., and Ermon, S.

 Generative modeling by estimating gradients of the data distribution.

 *Advances in neural information processing systems 32* (2019).

[70]
 Song, Y., and Ermon, S.

 Improved techniques for training score-based generative models.

 *Advances in neural information processing systems 33* (2020), 12438–12448. 

[71]
 Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B.

Score-based generative modeling through stochastic differential equations.

 *arXiv* preprint arXiv:2011.13456 (2020).

[72]
 Standard, S. H.

 Federal information processing standards publication 180-1, 1995.

[73]
 Subbarao, M., and Surya, G.

 Depth from defocus: A spatial domain approach.

International Journal of computer vision 13, 3 (1994), 271–294.

[74]
 Suwajanakorn, S., Seitz, S. M., and Kemelmacher-Shlizerman, I.

 Synthesizing obama: learning lip sync from audio.

 *ACM Transactions on Graphics (ToG) 36*, 4
(2017), 1–13.

[75]
 Tang, H., Cohen, S., Price, B., Schiller, S., and Kutulakos, K. N.

 Depth from defocus in the wild. In Proceedings of the IEEE conference on computer vision and pattern recognition (2017), pp. 2740–2748.

[76]
 Thies, J., Zollhöfer, M., and Niessner, M.

 Deferred neural rendering: Image synthesis using neural textures.

 *Acm Transactions on Graphics (TOG) 38*, 4 (2019),
1–12.

[77]
 Thies, J., Zollhofer, M., Stamminger, M., Theobalt, C., and Niessner, M.

Face2face: Real-time face capture and reenactment of rgb videos. In
 *Proceedings* of the IEEE conference on computer vision and pattern recognition (2016), pp. 2387–
2395.

[78]
 Tripathy, S., Kannala, J., and Rahtu, E.

 Facegan: Facial attribute controllable reenactment gan. In Proceedings of the IEEE/CVF winter conference on applications of computer vision (2021), pp. 1329–1338.

[79]
 Villalobos, P., Sevilla, J., Heim, L., Besiroglu, T., Hobbhahn, M., and Ho, A.

Will we run out of data? an analysis of the limits of scaling datasets in machine learning.

 *arXiv preprint arXiv:2211.04325* (2022).

[80]
 Wang, T.-C., Liu, M.-Y., Tao, A., Liu, G., Kautz, J., and Catanzaro, B.

 Few-shot video-to-video synthesis.

 *arXiv preprint arXiv:1910.12713* (2019).

[81]
 Wang, Z., Bao, J., Zhou, W., Wang, W., Hu, H., Chen, H., and Li, H.

 Dire for diffusion-generated image detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (2023), pp. 22445–22455.

[82]
 Watanabe, M., Nayar, S. K., and Noguchi, M. N.

 Real-time computation of depth from defocus. In Three-Dimensional and Unconventional Imaging for Industrial Inspection and Metrology (1996), vol. 2599, SPIE, pp. 14–25.

[83]
 Yang, L., Zhang, Z., Song, Y., Hong, S., Xu, R., Zhao, Y., Zhang, W., Cui, B.,
and Yang, M.-H.

 Diffusion models: A comprehensive survey of methods and applications.

 *ACM Computing Surveys 56*, 4 (2023), 1–39.

[84]
 Yu, F., and Gallup, D.

 3d reconstruction from accidental motion. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2014), pp. 3986–
3993.

[85]
 Zakharov, E., Shysheya, A., Burkov, E., and Lempitsky, V.

 Few-shot adversarial learning of realistic neural talking head models. In Proceedings of the IEEE/CVF
international conference on computer vision (2019), pp. 9459–9468.

[86]
 Zhang, J., Zeng, X., Pan, Y., Liu, Y., Ding, Y., and Fan, C.

 Faceswapnet: Landmark guided many-to-many face reenactment.

 *arXiv preprint arXiv:1905.11805 2* (2019),
3.

[87]
 Zhang, L., Yang, H., Qiu, T., and Li, L.

 Ap-gan: Improving attribute preservation in video face swapping.

 IEEE transactions on circuits and systems for video technology 32, 4 (2021), 2226–2237.

[88]
 Zhang, Q., and Chen, Y.

 Fast sampling of diffusion models with exponential integrator.

 *arXiv preprint arXiv:2204.13902* (2022).

[89]
 Zhang, Q., Tao, M., and Chen, Y.

 gddim: Generalized denoising diffusion implicit models.

 *arXiv preprint arXiv:2206.05564* (2022).

[90]
 Zhang, Y., Zhang, S., He, Y., Li, C., Loy, C. C., and Liu, Z.

 One-shot face reenactment.

 *arXiv preprint arXiv:1908.03251* (2019).

[91]
 Zhang, Z., Li, L., Ding, Y., and Fan, C.

 Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (2021), pp. 3661–
3670.

[92]
 Zhao, H., Zhou, W., Chen, D., Wei, T., Zhang, W., and Yu, N.

 Multi-attentional deepfake detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2021), pp. 2185–2194.

[93]
 Zheng, H., He, P., Chen, W., and Zhou, M.

 Truncated diffusion probabilistic models.

 *stat 1050* (2022), 7.

[94]
 Zhu, Y., Li, Q., Wang, J., Xu, C.-Z., and Sun, Z.

 One shot face swapping on megapixels. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (2021), pp. 4834–4844.

Received 20 February 2024; revised 20 February 2024; accepted 20 February 2024